{"id": "fc4dn6", "title": "Is this possible with Regex?", "url": "https://www.reddit.com/r/learnpython/comments/fc4dn6/is_this_possible_with_regex/", "subreddit": "learnpython", "author": "t2_5huxt23d", "text": "I have this text file called example2.txt:\n\nTime                          Source IP:          Destination IP    Packetlength\n\n('13:25:31.044845', '[10.247.15.39](https://10.247.15.39)', '[172.217.2.163](https://172.217.2.163)', 'length 0')\n\n('13:25:31.033303', '[10.247.15.39](https://10.247.15.39)', '[172.217.2.163](https://172.217.2.163)', 'length 46')\n\n('13:25:31.044180', '[172.217.2.161](https://172.217.2.161)', '[10.247.15.39](https://10.247.15.39)', 'length 0')\n\n('13:25:31.044371', '[172.217.2.161](https://172.217.2.161)', '[10.247.15.39](https://10.247.15.39)', 'length 46')\n\n&#x200B;\n\nIs it possible to create a regex that will save only the first time stamp with packets of the same pair source ip and destination ip and the last time stamp of the same pair source ip and destination ip. For example the top two packets in the example2.txt.\n\nAlso even after saving both those time stamps of a \"first time stamp\" and a \"last time stamp\", the regex will keep searching and doing the same things for every new pair with the same source ip and destination ip.", "comments": [{"id": "fj8ooju", "author": "xtthew", "body": "*Anything is possible with Regex*"}, {"id": "fj8lhul", "author": "Vaphell", "body": "I don't think regex is the right approach here.\nIs the following situation possible?\n\n    ('13:25:31.044845', '10.247.15.39', '172.217.2.163', 'length 0')\n    ('13:25:31.044180', '172.217.2.161', '10.247.15.39', 'length 0')\n    ('13:25:31.033303', '10.247.15.39', '172.217.2.163', 'length 46')\n    ('13:25:31.044371', '172.217.2.161', '10.247.15.39', 'length 46')\n    ('13:25:31.547873', '10.247.15.39', '172.217.2.163', 'length 46')\n\nAnyway\nidea 1: assuming the file is not huge, you can sort the contents of the file by keys of (ip1, ip2, timestamp) then use itertools.groupby with keys of (ip1, ip2). First/last item in any group are what you want.  \nApprox 5 lines of code.\n\nidea 2: iterate over rows and for each row update a dictionary indexed with (ip1, ip2) with values of first/last timestamp - create new entry if not present, update first/last as necessary."}, {"id": "fj8pf4s", "author": "bonferoni", "body": "Yea you dont need regex for this problem. Theres probably a much better way to do this but i would just make a new column that is the your two ip address fields concatenated. Make a unique vector of those bros and for loop through it subsetting the df by it. On each loop, after subsetting, take the max and min time stamp of the subsetted df and append it to some list.\n\nProbably not the most efficient, but would get the job done"}, {"id": "fj8vbpb", "author": "SaintLouisX", "body": "    from datetime import datetime as dt\n    \n    input_ = [('13:25:31.044845', '10.247.15.39', '172.217.2.163', 'length 0'),\n            ('13:25:31.033303', '10.247.15.39', '172.217.2.163', 'length 46'),\n            ('13:25:31.044180', '172.217.2.161', '10.247.15.39', 'length 0'),\n            ('13:25:31.044371', '172.217.2.161', '10.247.15.39', 'length 46'),\n            ('13:25:31.044845', '10.247.15.39', '172.217.2.163', 'length 0'),\n            ('13:25:31.111111', '10.247.15.39', '172.217.2.163', 'length 46'),]\n    \n    fmt = \"%H:%M:%S.%f\"\n    d = {}\n    for time,src,dst,len_ in input_:\n        if (src+dst) in d:\n            start = min(dt.strptime(d[(src+dst)], fmt),\n                        dt.strptime(time, fmt))\n            end = max(dt.strptime(d[(src+dst)], fmt),\n                        dt.strptime(time, fmt))\n            print(f\"{src:>15s} : {dst:<15s} -> {dt.strftime(start, fmt)} - {dt.strftime(end, fmt)}\")\n            del d[(src+dst)]\n        else:\n            d[(src+dst)] = time\n\nI don't know about regex, but can something like this work?\n\nEDIT: I just saw the timestamps were apparently out of order, this works in pairs and gets the min and max of the two timestamps, if that's what you expect."}, {"id": "fj94sib", "author": "Fumigenna", "body": "Anything is possible with regex!"}, {"id": "fj9680u", "author": "o5a", "body": "You can use regexp to parse your text file to nested list if it doesn't have proper structure already (say CSV).\n\nBut you would use other tools for your sorting and filtering. Aside from already suggested here, you can do it with pandas: sort by time, group by ips and take first and last rows in groups. Example:\n\n    import pandas as pd\n    \n    data = [('13:25:31.044845', '10.247.15.39', '172.217.2.163', 'length 0'),\n            ('13:25:31.033303', '10.247.15.39', '172.217.2.163', 'length 46'),\n            ('13:25:31.044180', '172.217.2.161', '10.247.15.39', 'length 0'),\n            ('13:25:31.044371', '172.217.2.161', '10.247.15.39', 'length 46'),\n            ('13:25:31.044845', '10.247.15.39', '172.217.2.163', 'length 0'),\n            ('13:25:31.111111', '10.247.15.39', '172.217.2.163', 'length 46'),]\n    \n    df = pd.DataFrame(data, columns=['timestamp', 'ip1', 'ip2', 'packetlength'])\n    \n    # sorting by time and grouping by ips\n    gdf = df.sort_values('timestamp').groupby(['ip1', 'ip2'])\n    \n    # forming new dataframe from first and last values in each group\n    new_df = gdf.first().append(gdf.last()).reset_index()\n    print(new_df)\n\n    # result:\n                 ip1            ip2                  timestamp packetlength\n    0   10.247.15.39  172.217.2.163 2020-03-02 13:25:31.033303    length 46\n    1  172.217.2.161   10.247.15.39 2020-03-02 13:25:31.044180     length 0\n    2   10.247.15.39  172.217.2.163 2020-03-02 13:25:31.111111    length 46\n    3  172.217.2.161   10.247.15.39 2020-03-02 13:25:31.044371    length 46"}]}